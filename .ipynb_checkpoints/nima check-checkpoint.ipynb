{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from path import Path\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from utils.score_utils import mean_score, std_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "s = 'f:/Avito/data/competition_files/train_jpg/'\n",
    "#s = 'f:/Avito/neural-image-assessment/extracted_images'\n",
    "imgs = Path(s).files('*.png')\n",
    "imgs += Path(s).files('*.jpg')\n",
    "imgs += Path(s).files('*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    base_model = InceptionResNetV2(input_shape=(None, None, 3), include_top=False, pooling='avg', weights=None)\n",
    "    x = Dropout(0.75)(base_model.output)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(base_model.input, x)\n",
    "    model.load_weights('f:/Avito/neural-image-assessment/weights/inception_resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "\n",
    "\n",
    "for img_path in tqdm.tqdm(imgs):\n",
    "    img = load_img(img_path, target_size=target_size)\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    scores = model.predict(x, batch_size=1, verbose=0)[0]\n",
    "\n",
    "    mean = mean_score(scores)\n",
    "    std = std_score(scores)\n",
    "\n",
    "    file_name = Path(img_path).name.lower()\n",
    "    score_list.append((file_name, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = preprocess_input(np.expand_dims(img_to_array(load_img(img_path, target_size=target_size)), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.empty((1, 3))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.36990317e-311, 0.00000000e+000, 0.00000000e+000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "score_list = np.empty((1, 3))\n",
    "step = 5#len(imgs) // 2\n",
    "i = 0\n",
    "while i < len(imgs):\n",
    "    #print(i)\n",
    "    imgs_temp = imgs[i:i+step]\n",
    "    img_array = None\n",
    "    file_names = []\n",
    "    for j in imgs_temp:\n",
    "        print(img_to_array(load_img(j, target_size=target_size)).shape)\n",
    "        x = preprocess_input(np.expand_dims(img_to_array(load_img(j, target_size=target_size)), axis=0))\n",
    "        img_array = x if img_array is None else np.vstack([img_array, x])\n",
    "        file_names.append(Path(j).name.lower())\n",
    "    i += step\n",
    "#     scores = model.predict(img_array, batch_size=len(img_array), verbose=0)\n",
    "    \n",
    "#     si = np.arange(1, 11, 1)\n",
    "    \n",
    "#     mean = np.sum(scores * si, axis=1)\n",
    "    \n",
    "#     std = np.sqrt(np.sum(((np.array([si,]*len(imgs_temp)) - mean.reshape(len(imgs_temp), -1)) ** 2) * scores, axis=1))\n",
    "\n",
    "#     result = np.stack([file_names, mean, std]).transpose()\n",
    "#     score_list = result if i == 0 else np.vstack([score_list, result])\n",
    "    \n",
    "   #  i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000725c906aa340744a2ead2f266d71c7e7b32c1f1509b18e0f412264b6c5e9.jpg',\n",
       " array([4.60270603, 4.07927945, 4.24003317, 4.69856544, 4.17791334,\n",
       "        4.59958921, 5.69586003]),\n",
       " array([1.45852858, 1.44356835, 1.55805358, 1.54437872, 1.56303498,\n",
       "        1.48322278, 1.4732546 ])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[file_name, mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = model.predict(img_array, batch_size=len(img_array), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02019363, 0.05189359, 0.12576899, 0.2659625 , 0.3069636 ,\n",
       "       0.14442056, 0.05397768, 0.02172789, 0.00635581, 0.00273576],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.602706026751548"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(q[0] * si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = np.arange(1, 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02019363, 0.05189359, 0.12576899, 0.2659625 , 0.3069636 ,\n",
       "        0.14442056, 0.05397768, 0.02172789, 0.00635581, 0.00273576],\n",
       "       [0.04346408, 0.08928581, 0.18210179, 0.31404376, 0.2391114 ,\n",
       "        0.08615473, 0.02995189, 0.01165265, 0.00294644, 0.00128757],\n",
       "       [0.04458367, 0.08357114, 0.16541235, 0.28125992, 0.25002676,\n",
       "        0.10684607, 0.04178426, 0.01813073, 0.00556602, 0.00281904],\n",
       "       [0.02264051, 0.0542    , 0.11616981, 0.24030954, 0.30637482,\n",
       "        0.1567584 , 0.06201715, 0.02722646, 0.00961325, 0.00469019],\n",
       "       [0.04854181, 0.09221178, 0.16815636, 0.27942157, 0.24645151,\n",
       "        0.10143348, 0.03892893, 0.01689762, 0.00531872, 0.00263822],\n",
       "       [0.02153154, 0.05462473, 0.12575096, 0.26377925, 0.30326012,\n",
       "        0.1432764 , 0.05500689, 0.02262056, 0.00702884, 0.00312072],\n",
       "       [0.00355995, 0.01186186, 0.03911171, 0.12269653, 0.28731605,\n",
       "        0.2818059 , 0.14717303, 0.06838121, 0.02515912, 0.01293464]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02019363, 0.10378718, 0.37730697, 1.06385005, 1.53481796,\n",
       "        0.86652339, 0.37784378, 0.17382313, 0.05720231, 0.02735763],\n",
       "       [0.04346408, 0.17857161, 0.54630536, 1.25617504, 1.19555697,\n",
       "        0.51692837, 0.20966321, 0.09322122, 0.02651792, 0.01287566],\n",
       "       [0.04458367, 0.16714229, 0.49623705, 1.1250397 , 1.25013381,\n",
       "        0.64107643, 0.2924898 , 0.14504582, 0.05009421, 0.0281904 ],\n",
       "       [0.02264051, 0.10840001, 0.34850943, 0.96123815, 1.53187409,\n",
       "        0.94055039, 0.43412005, 0.21781167, 0.08651927, 0.04690188],\n",
       "       [0.04854181, 0.18442355, 0.50446907, 1.11768627, 1.23225756,\n",
       "        0.60860087, 0.27250251, 0.13518099, 0.04786852, 0.02638219],\n",
       "       [0.02153154, 0.10924946, 0.37725288, 1.05511701, 1.51630059,\n",
       "        0.85965836, 0.38504821, 0.18096446, 0.06325953, 0.03120717],\n",
       "       [0.00355995, 0.02372371, 0.11733514, 0.49078611, 1.43658027,\n",
       "        1.69083542, 1.03021123, 0.5470497 , 0.22643209, 0.12934642]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q * si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.60270603, 4.07927945, 4.24003317, 4.69856544, 4.17791334,\n",
       "       4.59958921, 5.69586003])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.sum(q * si, axis=1)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     si = np.arange(1, 11, 1)\n",
    "#     mean = mean_score(scores)\n",
    "std = np.sqrt(np.sum(((si - mean) ** 2) * scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6917c69a7d93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (7,) "
     ]
    }
   ],
   "source": [
    "np.sqrt(np.sum(((si - mean) ** 2) * scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41212475, 0.38601852, 0.2121202 , 0.00197384, 0.20270102,\n",
       "       0.31783922, 0.25550782, 0.17912516, 0.07134348, 0.04513555])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((si - mean[1]) ** 2) * scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45852858, 1.44356835, 1.55805358, 1.54437872, 1.56303498,\n",
       "       1.48322278, 1.4732546 ])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(((np.array([si,]*7) - mean.reshape(7, -1)) ** 2) * scores, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.262103  , 0.35153125, 0.3230586 , 0.09661209, 0.0484519 ,\n",
       "        0.28197111, 0.31021074, 0.25077477, 0.12289723, 0.07969492],\n",
       "       [0.41212475, 0.38601852, 0.2121202 , 0.00197384, 0.20270102,\n",
       "        0.31783922, 0.25550782, 0.17912516, 0.07134348, 0.04513555],\n",
       "       [0.46803109, 0.41933899, 0.25435164, 0.01620505, 0.14440285,\n",
       "        0.33095392, 0.3182881 , 0.25632045, 0.12611097, 0.0935279 ],\n",
       "       [0.30970823, 0.39469828, 0.33516437, 0.11726954, 0.02783807,\n",
       "        0.2655067 , 0.3284801 , 0.29675398, 0.17786765, 0.13181871],\n",
       "       [0.49023021, 0.43738871, 0.23331355, 0.00884457, 0.16655846,\n",
       "        0.33675913, 0.31003674, 0.24684635, 0.12367374, 0.08942689],\n",
       "       [0.27898509, 0.36914649, 0.32175717, 0.09483054, 0.04862133,\n",
       "        0.28098656, 0.31694815, 0.26155683, 0.13610368, 0.09101396],\n",
       "       [0.07850083, 0.16202562, 0.2842507 , 0.352868  , 0.13912452,\n",
       "        0.02606736, 0.25030911, 0.36304003, 0.2746707 , 0.23962227]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array([si,]*7) - mean.reshape(7, -1)) ** 2) * scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.29794907e+01, 6.77407866e+00, 2.56866661e+00, 3.63254555e-01,\n",
       "        1.57842501e-01, 1.95243045e+00, 5.74701839e+00, 1.15416063e+01,\n",
       "        1.93361943e+01, 2.91307822e+01],\n",
       "       [9.48196193e+00, 4.32340303e+00, 1.16484413e+00, 6.28523104e-03,\n",
       "        8.47726333e-01, 3.68916743e+00, 8.53060854e+00, 1.53720496e+01,\n",
       "        2.42134907e+01, 3.50549318e+01],\n",
       "       [1.04978149e+01, 5.01774860e+00, 1.53768226e+00, 5.76159228e-02,\n",
       "        5.77549582e-01, 3.09748324e+00, 7.61741690e+00, 1.41373506e+01,\n",
       "        2.26572842e+01, 3.31772179e+01],\n",
       "       [1.36793864e+01, 7.28225546e+00, 2.88512457e+00, 4.87993681e-01,\n",
       "        9.08627910e-02, 1.69373190e+00, 5.29660101e+00, 1.08994701e+01,\n",
       "        1.85023392e+01, 2.81052083e+01],\n",
       "       [1.00991332e+01, 4.74330650e+00, 1.38747983e+00, 3.16531552e-02,\n",
       "        6.75826483e-01, 3.31999981e+00, 7.96417314e+00, 1.46083465e+01,\n",
       "        2.32525198e+01, 3.38966931e+01],\n",
       "       [1.29570424e+01, 6.75786404e+00, 2.55868563e+00, 3.59507215e-01,\n",
       "        1.60328804e-01, 1.96115039e+00, 5.76197198e+00, 1.15627936e+01,\n",
       "        1.93636152e+01, 2.91644368e+01],\n",
       "       [2.20511014e+01, 1.36593814e+01, 7.26766130e+00, 2.87594124e+00,\n",
       "        4.84221181e-01, 9.25011214e-02, 1.70078106e+00, 5.30906100e+00,\n",
       "        1.09173409e+01, 1.85256209e+01]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array([si,]*7) - mean.reshape(7, -1)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = np.arange(1, 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = np.sum(scores * si)\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.455874852836132"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.45587485, -2.45587485, -1.45587485, -0.45587485,  0.54412515,\n",
       "        1.54412515,  2.54412515,  3.54412515,  4.54412515,  5.54412515])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si - mean_score(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.45587485, 4.45587485, 4.45587485, 4.45587485, 4.45587485,\n",
       "       4.45587485, 4.45587485])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  1,  1,  1,  2,  2,  2],\n",
       "       [ 2,  2,  2,  2,  3,  3,  3,  3,  3,  3],\n",
       "       [ 3,  4,  4,  4,  4,  4,  4,  4,  5,  5],\n",
       "       [ 5,  5,  5,  5,  5,  6,  6,  6,  6,  6],\n",
       "       [ 6,  6,  7,  7,  7,  7,  7,  7,  7,  8],\n",
       "       [ 8,  8,  8,  8,  8,  8,  9,  9,  9,  9],\n",
       "       [ 9,  9,  9, 10, 10, 10, 10, 10, 10, 10]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(si, 7).reshape(-1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-da147e9c3306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (7,) "
     ]
    }
   ],
   "source": [
    "np.subtract(si, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "shuffle_data = False  # shuffle the addresses before saving\n",
    "hdf5_path = 'i:/dataset_train2.hdf5'  # address to where you want to save the hdf5 file\n",
    "cat_dog_train_path = 'f:/Avito/data/competition_files/train_jpg/*.jpg'\n",
    "# read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(cat_dog_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del hdf5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "# check the order of data and chose proper data shape to save images\n",
    "data_shape = (len(addrs[:1000]), 224, 224, 3)[:1000]\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"train_img\": shape (1390836, 224, 224, 3), type \"<f4\">"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_file.create_dataset(\"train_img\", data_shape, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrs = glob.glob(cat_dog_train_path)\n",
    "data_shape = (len(addrs[:1000]), 224, 224, 3)[:1000]\n",
    "img_array = np.empty(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array[1, ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7e71cfc8f84930bce3b4fd8f6d5c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in tqdm_notebook(range(len(addrs))[:1000]):\n",
    "    # print how many images are saved every 1000 images\n",
    "#     if i % 100000 == 0 and i > 1:\n",
    "#         print ('Train data: {}/{}'.format(i, len(addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = addrs[i]\n",
    "    img = cv2.imread(addr).astype(np.float32)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img_array = img[None] if img_array is None else np.vstack([img_array, img[None]])\n",
    "    img_array[i,] = img[None]\n",
    "    # save the image\n",
    "    #hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "#hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdf5_path_test = 'f:/Avito/neural-image-assessment/dataset_test1.hdf5'  # address to where you want to save the hdf5 file\n",
    "cat_dog_test_path = 'f:/Avito/data/competition_files/test_jpg/*.jpg'\n",
    "# read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(cat_dog_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"dataset_train.hdf5\" (mode r+)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_file = h5py.File(hdf5_path_test, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.create_dataset(\"test_img\", data_shape, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(len(addrs))):\n",
    "    # print how many images are saved every 1000 images\n",
    "#     if i % 100000 == 0 and i > 1:\n",
    "#         print ('Train data: {}/{}'.format(i, len(addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224, 3), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "#hdf5_path = 'Cat vs Dog/dataset.hdf5'\n",
    "subtract_mean = False\n",
    "# open the hdf5 file\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "# Total number of samples\n",
    "data_num = hdf5_file[\"train_img\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 7\n",
      "2 / 7\n",
      "3 / 7\n",
      "4 / 7\n",
      "5 / 7\n",
      "6 / 7\n",
      "7 / 7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "batches_list = list(range(data_num // batch_size))\n",
    "# loop over batches\n",
    "for n, i in enumerate(batches_list):\n",
    "    i_s = i * batch_size  # index of the first image in this batch\n",
    "    i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n",
    "    # read batch images and remove training mean\n",
    "    images = hdf5_file[\"train_img\"][i_s:i_e, ...]\n",
    "    print (n+1, '/', len(batches_list))\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[-0.45240999, -0.57855009, -0.78052187],\n",
       "          [-0.4539324 , -0.57295006, -0.79637162],\n",
       "          [-0.44141223, -0.5590592 , -0.78533663],\n",
       "          ...,\n",
       "          [-0.1293089 , -0.13715198, -0.17636767],\n",
       "          [-0.14005193, -0.14789518, -0.18711075],\n",
       "          [-0.15220504, -0.16004818, -0.19926393]],\n",
       "\n",
       "         [[-0.4639947 , -0.58314655, -0.80739006],\n",
       "          [-0.44767265, -0.56615283, -0.79082063],\n",
       "          [-0.4366926 , -0.55521085, -0.79599716],\n",
       "          ...,\n",
       "          [-0.12927456, -0.13711769, -0.17633338],\n",
       "          [-0.13794639, -0.14578953, -0.18500522],\n",
       "          [-0.14930791, -0.15715099, -0.19636673]],\n",
       "\n",
       "         [[-0.41847702, -0.52130327, -0.78104508],\n",
       "          [-0.39630755, -0.49905069, -0.75768979],\n",
       "          [-0.40145264, -0.50504955, -0.77500968],\n",
       "          ...,\n",
       "          [-0.13071038, -0.13855351, -0.1777692 ],\n",
       "          [-0.13794771, -0.14579091, -0.18500653],\n",
       "          [-0.14314856, -0.15099164, -0.19020739]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.12114054,  0.11329741,  0.08192474],\n",
       "          [ 0.12810657,  0.12026343,  0.08889112],\n",
       "          [ 0.14374904,  0.13590567,  0.10453312],\n",
       "          ...,\n",
       "          [ 0.30257173,  0.30946583,  0.27309714],\n",
       "          [ 0.28458539,  0.28458539,  0.268899  ],\n",
       "          [ 0.27034924,  0.27034924,  0.25466297]],\n",
       "\n",
       "         [[ 0.12104648,  0.11320322,  0.08183079],\n",
       "          [ 0.12019055,  0.11234741,  0.08097486],\n",
       "          [ 0.13480751,  0.12696414,  0.09559171],\n",
       "          ...,\n",
       "          [ 0.28282674,  0.28972084,  0.25335203],\n",
       "          [ 0.2698095 ,  0.2698095 ,  0.25412322],\n",
       "          [ 0.26738389,  0.26738389,  0.25169762]],\n",
       "\n",
       "         [[ 0.10713238,  0.09928936,  0.06791681],\n",
       "          [ 0.11878806,  0.11094492,  0.07957237],\n",
       "          [ 0.13582105,  0.12797792,  0.09660537],\n",
       "          ...,\n",
       "          [ 0.28304276,  0.28993686,  0.25356792],\n",
       "          [ 0.25829659,  0.25829659,  0.24261032],\n",
       "          [ 0.2616704 ,  0.2616704 ,  0.24598413]]],\n",
       "\n",
       "\n",
       "        [[[-0.27005759, -0.2845657 , -0.38221783],\n",
       "          [-0.71771782, -0.71701675, -0.77695058],\n",
       "          [-0.82389326, -0.81860933, -0.83766825],\n",
       "          ...,\n",
       "          [ 0.2894329 ,  0.23272035,  0.12642152],\n",
       "          [ 0.47878011,  0.43693118,  0.28612372],\n",
       "          [ 0.43150156,  0.36201758,  0.36106603]],\n",
       "\n",
       "         [[-0.27637233, -0.29716288, -0.37587202],\n",
       "          [-0.7481901 , -0.74699746, -0.80839268],\n",
       "          [-0.83653107, -0.83551927, -0.84172323],\n",
       "          ...,\n",
       "          [ 0.21904704,  0.10967443, -0.01619107],\n",
       "          [ 0.6064659 ,  0.5322219 ,  0.33807277],\n",
       "          [ 0.74172758,  0.65077239,  0.58650214]],\n",
       "\n",
       "         [[-0.34491182, -0.37006387, -0.43484264],\n",
       "          [-0.79447852, -0.80289691, -0.83795486],\n",
       "          [-0.83926591, -0.838572  , -0.84461745],\n",
       "          ...,\n",
       "          [ 0.10436246, -0.0654535 , -0.24360603],\n",
       "          [ 0.46351725,  0.34414422,  0.09267578],\n",
       "          [ 0.79242123,  0.67634469,  0.5306497 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.62154421, -0.63723052, -0.62938738],\n",
       "          [-0.7245712 , -0.73167072, -0.74902745],\n",
       "          [-0.67449335, -0.70794762, -0.7135519 ],\n",
       "          ...,\n",
       "          [ 0.63639275,  0.45551076,  0.30445652],\n",
       "          [ 0.2658622 ,  0.25624402,  0.22789067],\n",
       "          [ 0.46779414,  0.41847738,  0.38850624]],\n",
       "\n",
       "         [[-0.61270611, -0.62839239, -0.62054928],\n",
       "          [-0.69882854, -0.70592807, -0.72328482],\n",
       "          [-0.6696401 , -0.70309436, -0.70869868],\n",
       "          ...,\n",
       "          [ 0.48339628,  0.31075787,  0.15512181],\n",
       "          [-0.19429848, -0.20605337, -0.22406939],\n",
       "          [ 0.37248511,  0.32370426,  0.29837766]],\n",
       "\n",
       "         [[-0.60896358, -0.62464989, -0.61680675],\n",
       "          [-0.69198396, -0.69908349, -0.71644024],\n",
       "          [-0.67324949, -0.70670378, -0.7123081 ],\n",
       "          ...,\n",
       "          [ 0.26355986,  0.08943218, -0.05085192],\n",
       "          [-0.30074816, -0.31876556, -0.31416369],\n",
       "          [ 0.17211998,  0.11700894,  0.1094267 ]]],\n",
       "\n",
       "\n",
       "        [[[ 0.51646226,  0.19295343,  0.01888918],\n",
       "          [ 0.59506549,  0.14324101,  0.0409273 ],\n",
       "          [ 0.5841019 ,  0.12091962,  0.06228482],\n",
       "          ...,\n",
       "          [-0.22559521,  0.3303109 , -0.09006025],\n",
       "          [ 0.0794138 ,  0.62005005,  0.26475734],\n",
       "          [-0.01300605,  0.4752895 ,  0.24052675]],\n",
       "\n",
       "         [[ 0.35048924, -0.13548482, -0.34836899],\n",
       "          [ 0.4052416 , -0.15765321, -0.31004519],\n",
       "          [ 0.39354727, -0.14189447, -0.28290932],\n",
       "          ...,\n",
       "          [-0.66486245, -0.04423864, -0.46198252],\n",
       "          [-0.48656431,  0.09681672, -0.26271955],\n",
       "          [ 0.2400241 ,  0.77701607,  0.49008933]],\n",
       "\n",
       "         [[ 0.46175477, -0.10123207, -0.29063906],\n",
       "          [ 0.42654   , -0.14707085, -0.32990316],\n",
       "          [ 0.38815726, -0.14761233, -0.33429027],\n",
       "          ...,\n",
       "          [-0.65108346,  0.02599763, -0.36730191],\n",
       "          [-0.26064704,  0.38923495, -0.01599151],\n",
       "          [ 0.0385157 ,  0.62117872,  0.26283737]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.41959683,  0.13097438, -0.07370779],\n",
       "          [ 0.44847628,  0.15993174, -0.04396398],\n",
       "          [ 0.47061468,  0.18127202, -0.03078924],\n",
       "          ...,\n",
       "          [ 0.37974112,  0.08954504, -0.12224576],\n",
       "          [ 0.44165661,  0.15110641, -0.06148382],\n",
       "          [ 0.43817893,  0.15976263, -0.06605021]],\n",
       "\n",
       "         [[ 0.46337053,  0.18251079, -0.02155875],\n",
       "          [ 0.4824184 ,  0.20065978, -0.00206849],\n",
       "          [ 0.48243169,  0.2094267 , -0.00939768],\n",
       "          ...,\n",
       "          [ 0.38683699,  0.09664091, -0.11512385],\n",
       "          [ 0.41397047,  0.12303682, -0.0883591 ],\n",
       "          [ 0.34539185,  0.07251994, -0.14790673]],\n",
       "\n",
       "         [[ 0.45603279,  0.20078388,  0.0038588 ],\n",
       "          [ 0.48290333,  0.23417299,  0.01643485],\n",
       "          [ 0.504918  ,  0.24031061,  0.02183993],\n",
       "          ...,\n",
       "          [ 0.31195164,  0.02175556, -0.19000902],\n",
       "          [ 0.24611888, -0.04481488, -0.25621081],\n",
       "          [ 0.08900434, -0.18386787, -0.40429448]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.08761399, -0.1189866 , -0.12682968],\n",
       "          [-0.11399566, -0.14536815, -0.15321129],\n",
       "          [-0.11252082, -0.14389343, -0.15173657],\n",
       "          ...,\n",
       "          [-0.28651404, -0.58514964, -0.71955426],\n",
       "          [-0.27581135, -0.61660264, -0.76314578],\n",
       "          [-0.32403977, -0.6792613 , -0.82881097]],\n",
       "\n",
       "         [[-0.0761094 , -0.10748189, -0.11532515],\n",
       "          [-0.10409582, -0.13546831, -0.14331144],\n",
       "          [-0.10377365, -0.1351462 , -0.14298939],\n",
       "          ...,\n",
       "          [-0.33041831, -0.63243695, -0.77291993],\n",
       "          [-0.3197286 , -0.65962453, -0.80504137],\n",
       "          [-0.36149729, -0.71671882, -0.86886523]],\n",
       "\n",
       "         [[-0.04733127, -0.07870388, -0.08654701],\n",
       "          [-0.0867686 , -0.11814114, -0.12598422],\n",
       "          [-0.09645996, -0.12783263, -0.13567565],\n",
       "          ...,\n",
       "          [-0.29840465, -0.59985142, -0.74072702],\n",
       "          [-0.28127645, -0.62124876, -0.77569345],\n",
       "          [-0.32297824, -0.67819989, -0.8461549 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.46047651, -0.47616278, -0.46831964],\n",
       "          [-0.44656558, -0.46225185, -0.45440871],\n",
       "          [-0.42862746, -0.4443138 , -0.43647066],\n",
       "          ...,\n",
       "          [-0.69894379, -0.84433311, -0.91995488],\n",
       "          [-0.69308017, -0.83846947, -0.91409125],\n",
       "          [-0.69431849, -0.83970784, -0.91532961]],\n",
       "\n",
       "         [[-0.50150482, -0.51719109, -0.50934798],\n",
       "          [-0.49266854, -0.50835476, -0.50051165],\n",
       "          [-0.47267348, -0.48835982, -0.48051674],\n",
       "          ...,\n",
       "          [-0.71882318, -0.85900655, -0.93968091],\n",
       "          [-0.71207434, -0.8522577 , -0.93293208],\n",
       "          [-0.7138072 , -0.85399055, -0.93466492]],\n",
       "\n",
       "         [[-0.50711449, -0.52280076, -0.51495765],\n",
       "          [-0.49950717, -0.51519342, -0.50735031],\n",
       "          [-0.4791331 , -0.49481937, -0.48697623],\n",
       "          ...,\n",
       "          [-0.72266777, -0.87132696, -0.92731021],\n",
       "          [-0.7159863 , -0.86464549, -0.92062875],\n",
       "          [-0.71770304, -0.86636222, -0.92234548]]],\n",
       "\n",
       "\n",
       "        [[[ 0.82095863,  0.53860569,  0.28762542],\n",
       "          [ 0.82867192,  0.54631886,  0.29533859],\n",
       "          [ 0.82521171,  0.53798002,  0.30163562],\n",
       "          ...,\n",
       "          [ 0.70293914,  0.55826033,  0.41588853],\n",
       "          [ 0.23834252,  0.08477987, -0.02111727],\n",
       "          [-0.34148296, -0.44645888, -0.44339636]],\n",
       "\n",
       "         [[ 0.82786925,  0.54551631,  0.29549908],\n",
       "          [ 0.8289625 ,  0.54660944,  0.29559386],\n",
       "          [ 0.81954633,  0.53727453,  0.28605047],\n",
       "          ...,\n",
       "          [-0.24006019, -0.38224212, -0.47754983],\n",
       "          [-0.39818349, -0.55048583, -0.60802086],\n",
       "          [-0.5408838 , -0.65448145, -0.62587615]],\n",
       "\n",
       "         [[ 0.81729844,  0.5349455 ,  0.26591905],\n",
       "          [ 0.81442751,  0.53207457,  0.27329796],\n",
       "          [ 0.82290254,  0.5405496 ,  0.28073407],\n",
       "          ...,\n",
       "          [-0.44928786, -0.57119165, -0.59513298],\n",
       "          [-0.56488477, -0.69551212, -0.68630814],\n",
       "          [-0.60448321, -0.7225349 , -0.6708766 ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.36512331,  0.27360074,  0.17316009],\n",
       "          [-0.25735928, -0.21155814, -0.17036049],\n",
       "          [-0.46619849, -0.3247716 , -0.19566716],\n",
       "          ...,\n",
       "          [-0.14956085, -0.27313711, -0.28814769],\n",
       "          [-0.58660572, -0.64717186, -0.57941512],\n",
       "          [-0.75780523, -0.68667495, -0.66646088]],\n",
       "\n",
       "         [[ 0.76181317,  0.64272485,  0.52781659],\n",
       "          [ 0.00822383,  0.00948331,  0.02659409],\n",
       "          [-0.17086822, -0.06494571,  0.03546382],\n",
       "          ...,\n",
       "          [-0.38551731, -0.48967477, -0.49099684],\n",
       "          [-0.66439742, -0.69408282, -0.63181957],\n",
       "          [-0.85292981, -0.76520187, -0.75315205]],\n",
       "\n",
       "         [[ 0.79688422,  0.63483959,  0.50810966],\n",
       "          [-0.00552356, -0.02446756, -0.0255623 ],\n",
       "          [-0.1729208 , -0.10554175, -0.01928789],\n",
       "          ...,\n",
       "          [-0.38370523, -0.46134632, -0.46156191],\n",
       "          [-0.61442168, -0.61778971, -0.54898936],\n",
       "          [-0.85273352, -0.77693615, -0.7400916 ]]],\n",
       "\n",
       "\n",
       "        [[[ 1.        ,  1.        ,  1.        ],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          ...,\n",
       "          [ 0.99216189,  0.98612826,  1.00038249],\n",
       "          [ 0.9924229 ,  0.98391843,  0.99995871],\n",
       "          [ 0.99437495,  0.98615435,  1.        ]],\n",
       "\n",
       "         [[ 0.99999976,  0.99999976,  0.99999976],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          ...,\n",
       "          [ 0.99205574,  0.99205705,  0.9936016 ],\n",
       "          [ 1.00075564,  0.99979882,  1.00290599],\n",
       "          [ 1.0000426 ,  0.99947318,  1.00174213]],\n",
       "\n",
       "         [[ 1.        ,  1.        ,  1.        ],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          [ 1.        ,  1.        ,  1.        ],\n",
       "          ...,\n",
       "          [ 0.99564975,  0.9967862 ,  0.96954178],\n",
       "          [ 0.99263437,  0.99992257,  0.95517494],\n",
       "          [ 0.99624011,  1.0003193 ,  0.94878169]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.02118087, -0.16561327, -0.23427639],\n",
       "          [ 0.09923574, -0.05191112, -0.1047185 ],\n",
       "          [-0.03839207, -0.17151962, -0.23078206],\n",
       "          ...,\n",
       "          [ 0.23309015,  0.17546722,  0.16787827],\n",
       "          [ 0.07769177,  0.01695413, -0.01328089],\n",
       "          [ 0.17192862,  0.11859155,  0.05960167]],\n",
       "\n",
       "         [[ 0.04781901, -0.10120078, -0.15614989],\n",
       "          [-0.06660019, -0.21733482, -0.27137732],\n",
       "          [-0.03239561, -0.16552316, -0.22837794],\n",
       "          ...,\n",
       "          [ 0.13719255,  0.08834336,  0.08656796],\n",
       "          [ 0.41489126,  0.35446502,  0.32424436],\n",
       "          [ 0.31784668,  0.24476905,  0.18251403]],\n",
       "\n",
       "         [[ 0.01740794, -0.13161166, -0.18029815],\n",
       "          [ 0.03634476, -0.11438982, -0.16868029],\n",
       "          [ 0.20011968,  0.06699219,  0.00502978],\n",
       "          ...,\n",
       "          [ 0.7002281 ,  0.65085377,  0.66179989],\n",
       "          [ 0.1890862 ,  0.12224193,  0.0927209 ],\n",
       "          [ 0.31432088,  0.24381199,  0.18063845]]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_input(np.expand_dims(img_array, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1390836"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addrs = glob.glob(cat_dog_train_path)\n",
    "data_shape = (len(addrs[:1000]), 224, 224, 3)[:1000]\n",
    "img_array = np.empty(data_shape)\n",
    "for i in tqdm_notebook(range(len(addrs))[:1000]):\n",
    "    # print how many images are saved every 1000 images\n",
    "#     if i % 100000 == 0 and i > 1:\n",
    "#         print ('Train data: {}/{}'.format(i, len(addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = addrs[i]\n",
    "    img = cv2.imread(addr).astype(np.float32)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img_array = img[None] if img_array is None else np.vstack([img_array, img[None]])\n",
    "    img_array[i,] = img[None]\n",
    "    # save the image\n",
    "    #hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "#hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:29, 333.59it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-82afb47eb05b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#result = np.stack([file_names, mean, std]).transpose()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mscore_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all input arrays must have the same shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "score_list = np.empty((len(imgs), 11), dtype=object)\n",
    "step = 10000\n",
    "i = 0\n",
    "while i < len(imgs):\n",
    "    print(i)\n",
    "    imgs_temp = imgs[i:i + step]\n",
    "    img_array = np.empty((len(imgs_temp), 224, 224, 3))\n",
    "    file_names = []\n",
    "    for ind, j in tqdm.tqdm(enumerate(imgs_temp)):\n",
    "        x = preprocess_input(np.expand_dims(img_to_array(load_img(j, target_size=target_size)), axis=0))\n",
    "        img_array[ind, ] = x\n",
    "        file_names.append(Path(j).name.lower())\n",
    "\n",
    "    scores = model.predict(img_array, batch_size=100, verbose=0)\n",
    "\n",
    "    #si = np.arange(1, 11, 1)\n",
    "\n",
    "    #mean = np.sum(scores * si, axis=1)\n",
    "\n",
    "    #std = np.sqrt(np.sum(((np.array([si, ] * len(imgs_temp)) - mean.reshape(len(imgs_temp), -1)) ** 2) * scores, axis=1))\n",
    "\n",
    "    #result = np.stack([file_names, mean, std]).transpose()\n",
    "    result = np.stack([file_names, scores]).transpose()\n",
    "    score_list[i:i + step, ] = result\n",
    "    i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(file_names).reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list1 = np.empty((len(imgs), 11), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list1[i:i + step,0] = file_names\n",
    "score_list1[i:i + step,1:] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1390836, 11)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['00000acce78ccf00d3ca0c550cae60fb319d45861444b310559a47dac016c383.jpg',\n",
       "        '0.020193815', '0.051893856', '0.12576914', '0.2659623',\n",
       "        '0.30696338', '0.14442039', '0.05397763', '0.021727897',\n",
       "        '0.0063558356', '0.0027357794'], dtype=object),\n",
       " array(['00000acce78ccf00d3ca0c550cae60fb319d45861444b310559a47dac016c383.jpg',\n",
       "        0.020193815231323242, 0.05189385637640953, 0.12576913833618164,\n",
       "        0.26596230268478394, 0.30696338415145874, 0.14442038536071777,\n",
       "        0.05397763103246689, 0.021727897226810455, 0.0063558355905115604,\n",
       "        0.0027357793878763914], dtype=object))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list[0], score_list1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.hstack([np.array(file_names).reshape(-1, 1), scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list[i:i + step, ] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['00000acce78ccf00d3ca0c550cae60fb319d45861444b310559a47dac016c383.jpg',\n",
       "        '0.020193815', '0.051893856', ..., '0.021727897', '0.0063558356',\n",
       "        '0.0027357794'],\n",
       "       ['00001d464b8eb4f0f90b13b9194dc214c492cbe0c484fa9c53c393e3c8a6c599.jpg',\n",
       "        '0.04346374', '0.08928532', ..., '0.011652656', '0.0029464304',\n",
       "        '0.001287563'],\n",
       "       ['00002821738c1efaa7e73310f7a6e34d34ada6c68e08001166e17df45d9126a1.jpg',\n",
       "        '0.04458373', '0.0835712', ..., '0.018130679', '0.0055659977',\n",
       "        '0.0028190243'],\n",
       "       ...,\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None],\n",
       "       [None, None, None, ..., None, None, None]], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1390836, 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list[3,] = np.array([1, 'd', 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_scores_train = np.load('f:/Avito/neural-image-assessment/resnet_scores_train.npy')\n",
    "resnet_scores_test = np.load('f:/Avito/neural-image-assessment/resnet_scores_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_scores_train = pd.DataFrame(resnet_scores_train)\n",
    "resnet_scores_test = pd.DataFrame(resnet_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('f:/Avito/train.csv', usecols=['item_id', 'image'])\n",
    "test = pd.read_csv('f:/Avito/test.csv', usecols=['item_id', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_scores_train.columns = ['image'] + ['resnet_nima_feature_' + str(i) for i in range(10)]\n",
    "resnet_scores_test.columns = ['image'] + ['resnet_nima_feature_' + str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_scores_train['image'] = resnet_scores_train['image'].apply(lambda x: x.split('.')[0])\n",
    "resnet_scores_test['image'] = resnet_scores_test['image'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.merge(train, resnet_scores_train, how='left', on='image')\n",
    "test_features = pd.merge(test, resnet_scores_test, how='left', on='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('f:/Avito/resnet_scores_train.csv')\n",
    "test_features.to_csv('f:/Avito/resnet_scores_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNet_scores_train = np.load('f:/Avito/neural-image-assessment/MobileNet_scores_train.npy')\n",
    "MobileNet_scores_test = np.load('f:/Avito/neural-image-assessment/MobileNet_scores_test.npy')\n",
    "MobileNet_scores_train = pd.DataFrame(MobileNet_scores_train)\n",
    "MobileNet_scores_test = pd.DataFrame(MobileNet_scores_test)\n",
    "train = pd.read_csv('f:/Avito/train.csv', usecols=['item_id', 'image'])\n",
    "test = pd.read_csv('f:/Avito/test.csv', usecols=['item_id', 'image'])\n",
    "MobileNet_scores_train.columns = ['image'] + ['MobileNet_nima_feature_' + str(i) for i in range(10)]\n",
    "MobileNet_scores_test.columns = ['image'] + ['MobileNet_nima_feature_' + str(i) for i in range(10)]\n",
    "MobileNet_scores_train['image'] = MobileNet_scores_train['image'].apply(lambda x: x.split('.')[0])\n",
    "MobileNet_scores_test['image'] = MobileNet_scores_test['image'].apply(lambda x: x.split('.')[0])\n",
    "train_features = pd.merge(train, MobileNet_scores_train, how='left', on='image')\n",
    "test_features = pd.merge(test, MobileNet_scores_test, how='left', on='image')\n",
    "train_features.to_csv('f:/Avito/MobileNet_scores_train.csv')\n",
    "test_features.to_csv('f:/Avito/MobileNet_scores_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasnet_scores_train = np.load('f:/Avito/neural-image-assessment/nasnet_scores_train.npy')\n",
    "nasnet_scores_test = np.load('f:/Avito/neural-image-assessment/nasnet_scores_test.npy')\n",
    "nasnet_scores_train = pd.DataFrame(nasnet_scores_train)\n",
    "nasnet_scores_test = pd.DataFrame(nasnet_scores_test)\n",
    "train = pd.read_csv('f:/Avito/train.csv', usecols=['item_id', 'image'])\n",
    "test = pd.read_csv('f:/Avito/test.csv', usecols=['item_id', 'image'])\n",
    "nasnet_scores_train.columns = ['image'] + ['nasnet_nima_feature_' + str(i) for i in range(10)]\n",
    "nasnet_scores_test.columns = ['image'] + ['nasnet_nima_feature_' + str(i) for i in range(10)]\n",
    "nasnet_scores_train['image'] = nasnet_scores_train['image'].apply(lambda x: x.split('.')[0])\n",
    "nasnet_scores_test['image'] = nasnet_scores_test['image'].apply(lambda x: x.split('.')[0])\n",
    "train_features = pd.merge(train, nasnet_scores_train, how='left', on='image')\n",
    "test_features = pd.merge(test, nasnet_scores_test, how='left', on='image')\n",
    "train_features.to_csv('f:/Avito/nasnet_scores_train.csv')\n",
    "test_features.to_csv('f:/Avito/nasnet_scores_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'image', 'nasnet_nima_feature_0', 'nasnet_nima_feature_1',\n",
       "       'nasnet_nima_feature_2', 'nasnet_nima_feature_3',\n",
       "       'nasnet_nima_feature_4', 'nasnet_nima_feature_5',\n",
       "       'nasnet_nima_feature_6', 'nasnet_nima_feature_7',\n",
       "       'nasnet_nima_feature_8', 'nasnet_nima_feature_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MobileNet_nima_feature_0\n",
      "2 MobileNet_nima_feature_1\n",
      "3 MobileNet_nima_feature_2\n",
      "4 MobileNet_nima_feature_3\n",
      "5 MobileNet_nima_feature_4\n",
      "6 MobileNet_nima_feature_5\n",
      "7 MobileNet_nima_feature_6\n",
      "8 MobileNet_nima_feature_7\n",
      "9 MobileNet_nima_feature_8\n",
      "10 MobileNet_nima_feature_9\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(['MobileNet_nima_feature_0', 'MobileNet_nima_feature_1',\n",
    "       'MobileNet_nima_feature_2', 'MobileNet_nima_feature_3',\n",
    "       'MobileNet_nima_feature_4', 'MobileNet_nima_feature_5',\n",
    "       'MobileNet_nima_feature_6', 'MobileNet_nima_feature_7',\n",
    "       'MobileNet_nima_feature_8', 'MobileNet_nima_feature_9']):\n",
    "    print(i + 1, e)\n",
    "    train_features[e] = train_features[e] * (i + 1)\n",
    "    test_features[e] = test_features[e] * (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('f:/Avito/nasnet_scores_train_fixed.csv')\n",
    "test_features.to_csv('f:/Avito/nasnet_scores_test_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('f:/Avito/MobileNet_scores_train.csv')\n",
    "test_features = pd.read_csv('f:/Avito/MobileNet_scores_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('f:/Avito/MobileNet_scores_train_fixed.csv')\n",
    "test_features.to_csv('f:/Avito/MobileNet_scores_test_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
