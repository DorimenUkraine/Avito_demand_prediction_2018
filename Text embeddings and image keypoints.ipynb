{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embeddings and image keypoints\n",
    "\n",
    "In this notebook I do two things: use trained FastText model to process text data and convert it into 300-dimensional vector which can be used in models like LGB; I also extract keypoints from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import FastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from path import Path\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text embeddings\n",
    "\n",
    "If you want to use text in a non neural net model, there are many options:\n",
    "- use vectorizer and train model on created tokens;\n",
    "- reduce dimensionality after vectorizing the text;\n",
    "- create meta-features using other models;\n",
    "- vectorize text using word2vec-like models;\n",
    "- etc;\n",
    "\n",
    "In this notebook I use a pre-trained model to vectorize tet using FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText.load('embeddings/avito_big_150m_sg1.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['description'] = train['description'].apply(lambda x: str(x).replace('/\\n', ' ').replace('\\xa0', ' ').replace('.', '. ').replace(',', ', '))\n",
    "test['description'] = test['description'].apply(lambda x: str(x).replace('/\\n', ' ').replace('\\xa0', ' ').replace('.', '. ').replace(',', ', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for text in train['description']:\n",
    "    a = np.zeros((1, 300))\n",
    "    c = 0\n",
    "    for word in text.split():\n",
    "        if word in fasttext_model:\n",
    "            a += fasttext_model[word]\n",
    "            c += 1\n",
    "    a = a / c\n",
    "    vectors.append(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_test = []\n",
    "for text in test['description']:\n",
    "    a = np.zeros((1, 300))\n",
    "    c = 0\n",
    "    for word in text.split():\n",
    "        if word in fasttext_model:\n",
    "            a += fasttext_model[word]\n",
    "            c += 1\n",
    "    a = a / c\n",
    "    vectors_test.append(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_emb.npy', np.array(vectors))\n",
    "np.save('test_emb.npy', np.array(vectors_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting image keypoints\n",
    "\n",
    "In this competition there were a lot of ways which participants used images in the models. One of them is extracting keypoints from the images and creating a features showing a number of keypoints in the image.\n",
    "\n",
    "Keypoint is a name for an \"interesting point\" in the image - it could be an animal, a building and so on. So this could be useful for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'train_jpg/'\n",
    "imgs = Path(s).files('*.png')\n",
    "imgs += Path(s).files('*.jpg')\n",
    "imgs += Path(s).files('*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyp(img):\n",
    "    '''https://www.kaggle.com/c/avito-demand-prediction/discussion/59414#347781'''\n",
    "    try:        \n",
    "        img1 = cv2.imread(img,0)\n",
    "        fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "        # find and draw the keypoints\n",
    "        kp = fast.detect(img1,None)\n",
    "        kp = len(kp)\n",
    "        return  [img, kp]\n",
    "    except:\n",
    "        return [img, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.empty((len(imgs), 2), dtype=object)\n",
    "step = 20000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(imgs):\n",
    "    print(i)\n",
    "    imgs_temp = imgs[i:i + step]\n",
    "    features_temp = np.empty((len(imgs_temp), 2), dtype = object)\n",
    "    for ind, img in tqdm.tqdm(enumerate(imgs_temp)):\n",
    "        img_keys1 = keyp(img)\n",
    "        features_temp[ind, :] = img_keys1\n",
    "\n",
    "    features_train[i:i + step, :] = features_temp\n",
    "    i += step\n",
    "\n",
    "\n",
    "np.save('f:/Avito/train_keypoints.npy', features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading images\n"
     ]
    }
   ],
   "source": [
    "s = 'test_jpg/'\n",
    "print('reading images')\n",
    "imgs = Path(s).files('*.png')\n",
    "imgs += Path(s).files('*.jpg')\n",
    "imgs += Path(s).files('*.jpeg')\n",
    "\n",
    "features_test = np.empty((len(imgs), 2), dtype=object)\n",
    "step = 20000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:24, 235.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 239.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:25, 234.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:24, 235.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 240.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 239.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:26, 232.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:26, 231.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:27, 228.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:26, 230.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:25, 233.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:26, 231.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:27, 227.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:27, 229.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 238.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 239.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 238.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:24, 235.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:21, 244.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 238.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:22, 241.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:23, 238.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:22, 241.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5829it [00:24, 238.28it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(imgs):\n",
    "    print(i)\n",
    "    imgs_temp = imgs[i:i + step]\n",
    "    features_temp = np.empty((len(imgs_temp), 2), dtype = object)\n",
    "    for ind, img in tqdm.tqdm(enumerate(imgs_temp)):\n",
    "        img_keys1 = keyp(img)\n",
    "        features_temp[ind, :] = img_keys1\n",
    "\n",
    "    features_test[i:i + step, :] = features_temp\n",
    "    i += step\n",
    "\n",
    "\n",
    "np.save('f:/Avito/test_keypoints.npy', features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('f:/Avito/test_keypoints.npy', features_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
